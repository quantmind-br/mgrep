---
description: Rules for working with Qdrant storage, embeddings, and RAG (Ask) logic.
globs:
  - "src/lib/qdrant-store.ts"
  - "src/lib/providers/**/*.ts"
  - "src/lib/store.ts"
alwaysApply: false
---

# Storage & AI Provider Conventions

This rule covers the implementation of vector storage (Qdrant) and AI provider integrations.

## Vector Storage (Qdrant)
- **Chunking Strategy**: Source code is split into overlapping windows. Default: 50 lines per chunk with a 10-line overlap.
- **Payload Structure**: Every point in Qdrant must include:
  - `path`: Full relative path.
  - `path_scopes`: Array of parent directories for filtering.
  - `hash`: SHA256 of the file content.
  - `content`: The raw text of the chunk.
  - `start_line` / `num_lines`: Metadata for the chunk's location.

## AI Providers (`src/lib/providers/`)
- **Embeddings**: Implement `EmbeddingsClient`. Use `embedBatch` for efficiency during indexing.
- **LLM**: Implement `LLMClient`. Support `chat` and `chatStream`.
- **Adding a Provider**:
  1. Create implementation in `src/lib/providers/[embeddings|llm]/`.
  2. Register in the factory at `src/lib/providers/index.ts`.
  3. Update the Zod schema in `src/lib/config.ts`.

## RAG (Ask) Pipeline
The `store.ask()` method follows this flow:
1. **Embed**: Convert user question to a vector.
2. **Search**: Retrieve relevant chunks from Qdrant using the vector and path filters.
3. **Context**: Assemble chunks into a prompt.
4. **LLM**: Call the LLM to generate an answer.
5. **Citations**: The LLM should use `<cite i="...">` tags which the CLI parses to link back to source chunks.

## Performance Limits
- **Batching**: Embeddings should be generated in batches (default 100).
- **Timeouts**: 30s for embeddings, 60s for LLM requests.
- **Retries**: Implement a retry mechanism (default 3) for transient API errors.
